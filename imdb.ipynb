{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haUUbAip1yDE"
      },
      "source": [
        "# Overfitting on the IMDB movie reviews dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alo9UeDCuPPV"
      },
      "source": [
        "In this notebook we shall focus on overfitting, demonstrating the phenomenon and studying techniques to address it. The dataset we shall use is the IMDB movie reviews dataset, composed of 25,000 movies reviews, labeled by sentiment (positive/negative).\n",
        "\n",
        "To prevent overfitting, the best solution is to use more training data. When that is not a\n",
        "viable possibility, you can try to use regularization techniques, constraining the quantity and quality of information stored by the model. If a network can only afford to memorize a small number of patterns, the optimization process will force it to focus on the most prominent ones, which have a better chance of generalizing well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BSk2z9PFZ-9L"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import imdb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztsNnb6iwK9C"
      },
      "source": [
        "Let us load the dataset. In keras, the dataset is preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJPbQOuMarDA",
        "outputId": "34d00311-2c8c-4991-cb85-b99e57e61d8a"
      },
      "outputs": [],
      "source": [
        "num_words = 500\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
        "                                                      num_words=num_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRXaS5dmMpCF"
      },
      "source": [
        "Let us a look at the encoding of the first review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQjD51tfbAwr",
        "outputId": "0f18dc38-83c5-4fd3-e988-9d6e0e393c8e"
      },
      "outputs": [],
      "source": [
        "sample = x_train[320]\n",
        "print(len(sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_52OeyDw7-2"
      },
      "source": [
        "This representation has a variable length dimension, that is not very stuitable for a neural network.\n",
        "\n",
        "Let us transform it into a multi_hot encoding of of dimension equal to num_words. In this representation, a word gets index 1 if it appears in the document. It is essentially a bag-of-words encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "alcGwlTXbK83"
      },
      "outputs": [],
      "source": [
        "def multi_hot_sequences(sequences, dimension):\n",
        "  multi_hot = np.zeros((len(sequences),dimension))\n",
        "  for i in range(0,len(sequences)):\n",
        "    multi_hot[i, sequences[i]] = 1\n",
        "  return multi_hot\n",
        "\n",
        "x_train = multi_hot_sequences(x_train, num_words)\n",
        "x_test = multi_hot_sequences(x_test, num_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FqTkPgxeS3"
      },
      "source": [
        "Let us have a look at the initial part of the encoding for the first review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEqk4W3nbaOi",
        "outputId": "fcabbc58-47d5-4c84-f8e1-29f657409171"
      },
      "outputs": [],
      "source": [
        "print(x_train[0,0:30])\n",
        "print(x_train[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaJM6ZdCxnu0"
      },
      "source": [
        "We now define our first model, that is just a concatenation of three dense layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fIh5mHNDbncA"
      },
      "outputs": [],
      "source": [
        "seq = Input(shape=(num_words,))\n",
        "x = Dense(64, activation='relu')(seq)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "base_model = Model(seq, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "UDCNRoQLbszt",
        "outputId": "44ac5cb9-5776-4f52-e4bb-13b0470f332c"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg7OlD3px5b5"
      },
      "source": [
        "We compile the model using adam as optimizer, and binary crossentropy (log likelyhood) as loss function. The fit function returns a history of the training, that can be later inspected. In addition to the loss function, that is the canonical metric used for training, we also ask the model to keep trace of accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zN2Z1A6KcD5U"
      },
      "outputs": [],
      "source": [
        "base_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVhduLsrcObg",
        "outputId": "5b40ec89-821a-40f6-e8eb-d797cbe747af"
      },
      "outputs": [],
      "source": [
        "base_history = base_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs = 10,\n",
        "    batch_size = 512,\n",
        "    validation_data = (x_test, y_test),\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlIRDSnNy57N"
      },
      "source": [
        "Let us see the keys available in our history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C0VudEIciL1",
        "outputId": "fcb3451d-3301-4c8b-934b-0bc86ad3285a"
      },
      "outputs": [],
      "source": [
        "print(base_history.history.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsvLwbjLzFUf"
      },
      "source": [
        "The following function allows us to plot the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "7TdM-_YpcyiZ",
        "outputId": "4390a6ed-bf84-442d-fd2a-c676ee4a2d2d"
      },
      "outputs": [],
      "source": [
        "def plot_history(model_history,keys):\n",
        "    m,val_m = keys\n",
        "    plt.plot(model_history.history[m])\n",
        "    plt.plot(model_history.history[val_m])\n",
        "    plt.ylabel(m)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "plot_history(base_history,['accuracy','val_accuracy'])\n",
        "plot_history(base_history,['loss','val_loss'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXZ69_z61pTC"
      },
      "source": [
        "# Weight regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHH_DWlGL1Iu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s22gY8U1dkYo"
      },
      "outputs": [],
      "source": [
        "from keras import regularizers\n",
        "\n",
        "seq = Input(shape=(num_words,))\n",
        "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.005))(seq)\n",
        "x = Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.005))(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "l2reg_model = Model(seq, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VDnk7L2Eeh7q"
      },
      "outputs": [],
      "source": [
        "l2reg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fuUgMPpewd_",
        "outputId": "83bc7a15-7ce7-42e1-bf25-d29a60e08ca6"
      },
      "outputs": [],
      "source": [
        "l2reg_history = l2reg_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs = 10,\n",
        "    batch_size = 512,\n",
        "    validation_data = (x_test, y_test),\n",
        "    verbose = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "t3TrT7ydfVgw",
        "outputId": "789fa115-90e7-4f56-930b-5ddc3fd6fe5a"
      },
      "outputs": [],
      "source": [
        "plot_history(l2reg_history,['accuracy','val_accuracy'])\n",
        "plot_history(l2reg_history,['loss','val_loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZs5oVRF0LAK"
      },
      "source": [
        "# Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtVCugQW09_1"
      },
      "source": [
        "Dropout is an alternativeregularization techniques for neural networks. It consists of randomly “dropping out” (i.e. set to zero) a number of output features of the layer during training.\n",
        "\n",
        "At test time, no units are dropped out, but the layer’s output values are scaled down by a factor equal to the dropout rate, so as to balance for the fact that more units are active than at training time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i_ZA6nn3hI8G"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dropout\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyCHPs5W1XNo"
      },
      "source": [
        "Let’s add a couple of dropout layers in our IMDB network and see how it performs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XNNVUxxThTtO"
      },
      "outputs": [],
      "source": [
        "seq = Input(shape=(num_words,))\n",
        "x = Dense(64, activation='relu')(seq)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "dropout_model = Model(seq, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MtwSyEeYh5jS"
      },
      "outputs": [],
      "source": [
        "dropout_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "E-BUqoVgq1NE",
        "outputId": "a7bc6fb4-9193-477d-fb55-8f91d7420e33"
      },
      "outputs": [],
      "source": [
        "dropout_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdubTd_ViHz4",
        "outputId": "3c371bcd-d75e-49f1-c9c3-dfc165b7793e"
      },
      "outputs": [],
      "source": [
        "dropout_history = dropout_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs = 10,\n",
        "    batch_size = 512,\n",
        "    validation_data = (x_test, y_test),\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "Wan5Jqhui3Rm",
        "outputId": "882ca4b1-4558-42b4-ab6b-5d34b7814707"
      },
      "outputs": [],
      "source": [
        "plot_history(dropout_history,['accuracy','val_accuracy'])\n",
        "plot_history(dropout_history,['loss','val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LGylsBlkqgsr"
      },
      "outputs": [],
      "source": [
        "seq = Input(shape=(num_words,))\n",
        "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.005))(seq)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.005))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "mixed_model = Model(seq, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gD69SdvUrWD_"
      },
      "outputs": [],
      "source": [
        "adam = optimizers.Adam(learning_rate=0.001)\n",
        "mixed_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwsSSHyargi6",
        "outputId": "ae5f5bb1-f2f9-4f66-94c4-385990bd963e"
      },
      "outputs": [],
      "source": [
        "mixed_history = mixed_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs = 5,\n",
        "    batch_size = 512,\n",
        "    validation_data = (x_test, y_test),\n",
        "    verbose = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQPVeOrtM8Lf"
      },
      "source": [
        "# Early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGRc8KPkS5cN"
      },
      "source": [
        "Early stopping is a method that allows you to stop training as soon as the model performance stops improving on the validation dataset.\n",
        "\n",
        "This requires that a validation set must be provided to the fit() function.\n",
        "\n",
        "Early stopping can be simply implemented in keras using callbacks.\n",
        "A callback is a function taht is called at specific stages of the training procedure: start/end of epochs, start end of minibatches, etc.\n",
        "\n",
        "You can use callbacks to get a view on internal states and statistics of the model during training. A list of callbacks can be passed to the .fit() function using the keyword argument \"callbacks\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "x-ZKC8eqNAxd"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "\n",
        "saveDir = os.path.join(os.getcwd(), 'saved_models/')\n",
        "if not os.path.isdir(saveDir):\n",
        "    os.makedirs(saveDir)\n",
        "\n",
        "es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
        "chkpt = saveDir + 'imdb.h5'\n",
        "\n",
        "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvoIFERUP7Wl",
        "outputId": "bf08b312-e572-445a-a898-e21eeb6d4904"
      },
      "outputs": [],
      "source": [
        "mixed_model.fit(x_train, y_train,\n",
        "                batch_size=512, #batch_size,\n",
        "                epochs= 50,\n",
        "                verbose=1,\n",
        "                validation_data=(x_test,y_test),\n",
        "                callbacks=[es_cb, cp_cb],\n",
        "                shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLIxE8L6RTRk",
        "outputId": "2810fa25-2ff7-4749-fd84-ff0e680b1dad"
      },
      "outputs": [],
      "source": [
        "loss,acc = mixed_model.evaluate(x_test,y_test)\n",
        "print(\"test loss = \", loss)\n",
        "print(\"test accuracy = \", acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
