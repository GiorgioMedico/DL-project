{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdJWYFlSYr2a"
      },
      "source": [
        "In this notebook we build a simple auotencoder for Mnist data, and show how to use it for anomaly detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfzis0VRTzx4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUejWwcHYqyC"
      },
      "source": [
        "Both the encoder and the decoder are just composed by a couple of dense layers.\n",
        "The latent dimension is 16. This means that each input is reduced from an initial dimensions of 28*28=784 to a an internal dimension of just 16 floats.\n",
        "\n",
        "Most of the relevant information is preserved, as testified by the fact that we are able to reconstruct, out of this 16 values, an image very similar to the original one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTo6QGjpUL-6"
      },
      "outputs": [],
      "source": [
        "# size of our encoded representations\n",
        "encoding_dim = 16 \n",
        "mid_dim = 64\n",
        "\n",
        "# input placeholder\n",
        "input_img = layers.Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = layers.Dense(mid_dim, activation='relu')(input_img)\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = layers.Dense(mid_dim, activation='relu')(encoded)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxo-bQN_UpeW",
        "outputId": "1c433068-180d-4b36-ad28-f18a372df307"
      },
      "outputs": [],
      "source": [
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6oO__LvanuN"
      },
      "source": [
        "We can now compile the model. \n",
        "\n",
        "As loss function we can take mse or categorical crossentropy, as you prefer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4ynuGg2U5Yf"
      },
      "outputs": [],
      "source": [
        "adam = Adam(lr=0.001)\n",
        "autoencoder.compile(optimizer=adam, loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QkSZJw9bC4M"
      },
      "source": [
        "We now load the datatet, and normalize it in the range [0,1]. We are not using labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrxbCjv_VEr_",
        "outputId": "75e6942d-8c6d-4dbf-8613-621f729dc347"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f0kaHulbS8V"
      },
      "source": [
        "Time to fit the model. Observe that the ground truth we need to compare with is in this case the input itself. In other words, the loss is the distance between the inout $X$ and its reconstruction $\\hat{X}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrHB6uf4VP2D",
        "outputId": "0caa2ccd-9f6b-4094-f6fa-e84e01130b8a"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=20,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yXRGD2rb-gd"
      },
      "source": [
        "Let us check the result.\n",
        "\n",
        "First of all we conpute all reconstructions for images in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drKSjCmIVkr7"
      },
      "outputs": [],
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMBrchCtcRhL"
      },
      "source": [
        "Now we can plot the result. We pick ten random images, and for each of them we show the original and the reconstruction obtained from the autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "2I8qdO3rV9OE",
        "outputId": "96bf0fe2-8497-4da3-819a-e9dcb56646d0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10 #no images to plot\n",
        "imgs = np.random.randint(low=0,high=10000,size=n)\n",
        "plt.figure(figsize=(20, 4))\n",
        "for (i,idx) in enumerate(imgs):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[idx].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[idx].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkRApEXofHuz"
      },
      "source": [
        "# Anomaly detection\n",
        "\n",
        "We want now to show how we can use an autoencoder for anomaly detection.\n",
        "\n",
        "The genral idea is that the encoding learned by the autoenoder is data-specific. This means that if we apply the autoencoder to an outlier, the resulting reconstruction should be sensibily worse than usual, and we may exploit this simple fact to detect the anomaly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvuJQDk6f9dY"
      },
      "source": [
        "The first step of the procedure is to identify the canonical expected reconstruction error on true data, and the associated standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P1yRXhTgWj1",
        "outputId": "49126bdb-3615-4b4d-a6a1-7ce912c4eac8"
      },
      "outputs": [],
      "source": [
        "mse_all = np.mean(np.square(decoded_imgs - x_test),axis=1) #mean error for each input\n",
        "print(mse.shape) \n",
        "mse = np.mean(mse_all)\n",
        "std = np.std(mse_all)\n",
        "print(\"mse is {}, with a standard deviation of {}\".format(mse,std))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfydyrtLh-Eh"
      },
      "source": [
        "Now we create an \"anomaly\". We simply take a normal image from the dataset, and rotate it of 90 degrees. \n",
        "\n",
        "For this example, we use image no 15 in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "Znt0h6BFiqjl",
        "outputId": "6afefd5b-8469-40f0-d2c6-863dfa206e6f"
      },
      "outputs": [],
      "source": [
        "test = x_test[15].reshape(1,784)\n",
        "print(autoencoder.evaluate(test,test))\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "ax = plt.subplot(1,2,1)\n",
        "plt.imshow(x_test[15].reshape(28, 28))\n",
        "plt.gray()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.imshow(decoded_imgs[15].reshape(28, 28))\n",
        "plt.gray()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "plt.savefig('lyar1.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUCMrEjCi7gq"
      },
      "source": [
        "Observe that the reconstruction is not particularly good, but still the loss (0.207) is more or less on std away from the mean, that is a normal behaviour.\n",
        "\n",
        "Now, let us rotate it and repeat the computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "V2jM4Hfzjfju",
        "outputId": "ce7ac12a-f994-4222-93d9-6a7da71e9ae0"
      },
      "outputs": [],
      "source": [
        "rotated = np.rot90(x_test[15].reshape(28,28))\n",
        "predicted = autoencoder.predict(rotated.reshape(1,784))[0].reshape(28,28)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "ax = plt.subplot(1,2,1)\n",
        "plt.imshow(rotated)\n",
        "plt.gray()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.imshow(predicted)\n",
        "plt.gray()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "plt.savefig('lyar2.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLpUNUAvkSV9",
        "outputId": "56dcc164-98bf-4ab5-d29c-35e46c197703"
      },
      "outputs": [],
      "source": [
        "mse = np.mean(np.square(predicted-rotated))\n",
        "print(\"mse is {}\".format(mse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBuqr7o5ksM5"
      },
      "source": [
        "The mse in this case is 0.052, more than 3 std away form the mean, that is surely an anomaly!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpwnCIrkk601"
      },
      "source": [
        "Let us finally observe that, instead of using mean and variance of reconstruction errors, we could have directly worked in the latent space.\n",
        "\n",
        "In fact, autoencoders generalize Principal Component Ananlysis, extracting relevant, non linear combinations of the input features. Any anomaly will \n",
        "sensibibly discost from canonical values of the latent encoding."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "anomaly_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
