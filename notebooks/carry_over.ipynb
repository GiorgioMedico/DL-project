{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw_326KLT9dF"
      },
      "source": [
        "The purpose of this notebook is to show the use of LSTMs for processing sequences. \n",
        "\n",
        "Specifically, we try to compute the sum of two binay digits,\n",
        "delegating to the model the task of taking care of the propagation of the carry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynz-4_4cFmbJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Conv1D, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA01pkKbUt7Q"
      },
      "source": [
        "Here is our generator. Each element of the resulting batch is a pair (a,res)\n",
        "where a[0] and a[1] are two sequences of lenght seqlen of binary digits, and\n",
        "res is their sum. The digits are supposed to be represented in a positional order with less significative digits at lower positions (left to rigth).\n",
        "\n",
        "The initial carry of the generator is 0; at successive invocations it \n",
        "reuses the final carry of the previous sum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXSV0bfjF64L"
      },
      "outputs": [],
      "source": [
        "def generator(batchsize,seqlen):\n",
        "    init_carry = np.zeros(batchsize)\n",
        "    carry = init_carry\n",
        "    while True:\n",
        "      #print(\"initial carry = \", carry)\n",
        "      a = np.random.randint(2,size=(batchsize,seqlen,2))\n",
        "      res = np.zeros((batchsize,seqlen))\n",
        "      for t in range(0,seqlen):\n",
        "        sum = a[:,t,0]+a[:,t,1] + carry\n",
        "        res[:,t] = sum % 2\n",
        "        carry = sum // 2\n",
        "      yield (a, res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-jlaqAWc2o"
      },
      "source": [
        "Let's create an instance of the generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov3rXaLVHDCT"
      },
      "outputs": [],
      "source": [
        "gen = generator(1,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4hntQtSWjPk"
      },
      "source": [
        "And now let's see a few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM7R8ZZZHN7p",
        "outputId": "bb0e07ae-9efe-4644-ed04-a3417a46ed73"
      },
      "outputs": [],
      "source": [
        "a,res = next(gen)\n",
        "print(\"a1 = {}, a2={}. res = {}\".format(a[0,:,0],a[0,:,1],res[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD8Yg_HnWqYf"
      },
      "source": [
        "We can now define the model. It takes in input a pair of boolean sequences of unspecified length. The batchsize dimension is, as usual, implicit too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8FmUlpPOfcG"
      },
      "outputs": [],
      "source": [
        "def gen_model():\n",
        "    xa = Input(shape=(None,2))\n",
        "    x = Conv1D(8,1,activation='relu')(xa)\n",
        "    x = Conv1D(4,1,activation='relu')(x)\n",
        "    #x = xa\n",
        "    x = LSTM(4,activation=None, return_sequences=True)(x)\n",
        "    x = Dense(1,activation='sigmoid')(x)\n",
        "    out = tf.squeeze(x,2)\n",
        "    #out = x\n",
        "    comp = Model(inputs=xa, outputs=out)\n",
        "    return comp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHhEwRibOpgV",
        "outputId": "5f4d7095-b28b-4764-cc44-abf93aca0d39"
      },
      "outputs": [],
      "source": [
        "mymodel = gen_model()\n",
        "mymodel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHiUjmFKQB_p"
      },
      "outputs": [],
      "source": [
        "mymodel.compile(optimizer='adam',loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQwv4HCfQn11"
      },
      "outputs": [],
      "source": [
        "batchsize=100\n",
        "seqlen=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsV-U31gQdsl"
      },
      "outputs": [],
      "source": [
        "#mymodel.load_weights(\"weights/lstm.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSAUJlQnQWht",
        "outputId": "fda8abd0-4292-45c1-c227-9017ebcbf3f9"
      },
      "outputs": [],
      "source": [
        "mymodel.fit(generator(batchsize,seqlen), steps_per_epoch=100, epochs=100)\n",
        "#comp.save_weights(\"weights/lstm.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCI2sFv5SJ7O",
        "outputId": "231ff033-f6cb-4e14-e57a-abbf7d870249"
      },
      "outputs": [],
      "source": [
        "example,res = next(generator(1,10))\n",
        "predicted = np.array([int(np.rint(x)) for x in mymodel.predict(example)[0]])\n",
        "\n",
        "print(\"a1        = {}\".format(example[0][:,0].astype(int)))\n",
        "print(\"a2        = {}\".format(example[0][:,1].astype(int)))\n",
        "print(\"expected  = {}\".format(res[0].astype(int)))\n",
        "print(\"predicted = {}\".format(predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bU4ykMqXLan"
      },
      "source": [
        "WOW!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
