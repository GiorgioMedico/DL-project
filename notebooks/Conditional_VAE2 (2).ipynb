{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_DKvNpcIeVu"
      },
      "source": [
        "In this notebook we shall present a simple conditional VAE, trained on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8_HUth4IW1g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import utils\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKj7GMTI7eK2"
      },
      "source": [
        "The conditional autoencoder will allow to generate specific digits in the MNIST range 0-9. The condition is passed as input to encoder and decoder in categorical format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WG8B8RJlAaW"
      },
      "outputs": [],
      "source": [
        "# train the VAE on MNIST digits\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train),28,28,1))\n",
        "x_test = x_test.reshape((len(x_test),28,28,1))\n",
        "y_train = utils.to_categorical(y_train)\n",
        "y_test = utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxLa37ZnKIUV"
      },
      "source": [
        "# The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPu8FwnGJ5Pl"
      },
      "source": [
        "Sampling function for the Variational Autoencoder.\n",
        "This is the clsed form of the Kullback-Leibler distance between a gaussian N(z_mean,z_var) and a normal prior N(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1hiFRyHJbKf"
      },
      "outputs": [],
      "source": [
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
        "                              stddev=1.)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwm4jR5E8in4"
      },
      "source": [
        "Main dimensions for the model (a simple stack of dense layers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT9baosbKW8M"
      },
      "outputs": [],
      "source": [
        "input_dim = (28,28,1)\n",
        "latent_dim = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9atMqlZUJ_dD"
      },
      "outputs": [],
      "source": [
        "x = layers.Input(shape=input_dim)\n",
        "c = layers.Input(shape=(10,))\n",
        "cv = layers.Lambda(lambda x: tf.expand_dims(x,axis=1))(c)\n",
        "cv = layers.Lambda(lambda x:tf.expand_dims(x,axis=1))(cv)\n",
        "cv = layers.UpSampling2D((28,28), interpolation='nearest')(cv)\n",
        "y = layers.concatenate([x,cv])\n",
        "y = layers.Conv2D(16,(3,3),strides=(2,2),padding='same')(y)\n",
        "y = layers.BatchNormalization()(y)\n",
        "y = layers.Activation('swish')(y)\n",
        "y = layers.Conv2D(16,(3,3),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2D(32,(3,3),strides=(2,2),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2D(32,(3,3),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2D(64,(3,3),strides=(2,2),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2D(64,(3,3),activation='swish',padding='same')(y)\n",
        "y = layers.Flatten()(y)\n",
        "y = layers.Dense(64,activation='swish')(y)\n",
        "z_mean = layers.Dense(latent_dim)(y)\n",
        "z_log_var = layers.Dense(latent_dim)(y)\n",
        "encoder = Model([x,c],[z_mean,z_log_var])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "533QeAx09JGh"
      },
      "source": [
        "We start with the encoder. It takes two inputs: the image and the category.\n",
        "\n",
        "It returns the latent encoding (z_mean) and a (log-)variance for each latent variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "VLwi8KfAm0Ae",
        "outputId": "d6611f92-9780-4425-8103-39790090574c"
      },
      "outputs": [],
      "source": [
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUL-X_iT-Omd"
      },
      "source": [
        "Now we need to address the decoder. We first define its layers, in order to use them both in the vae model and in the stand-alone generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL94ost69tn_"
      },
      "source": [
        "Now we sample around z_mean with the associated variance.\n",
        "\n",
        "Note the use of the \"lambda\" layer to transform the sampling function into a keras layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlyP964wrCFr"
      },
      "outputs": [],
      "source": [
        "x = layers.Input(shape=(latent_dim,))\n",
        "c = layers.Input(shape=(10,))\n",
        "y = layers.concatenate([x,c])\n",
        "y = layers.Dense(128,activation='swish')(y)\n",
        "y = layers.concatenate([x,c])\n",
        "y = layers.Dense(1024,activation='swish')(y)\n",
        "y = layers.Reshape((4,4,64))(y)\n",
        "y = layers.Conv2D(64,(3,3),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2DTranspose(32,(3,3),strides=(2,2),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2D(32,(3,3),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2DTranspose(16,(3,3),strides=(2,2),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2D(16,(3,3),activation='swish',padding='valid')(y)\n",
        "y = layers.Conv2DTranspose(16,(3,3),strides=(2,2),activation='swish',padding='same')(y)\n",
        "y = layers.Conv2D(16,(3,3),padding='same')(y)\n",
        "y = layers.BatchNormalization()(y)\n",
        "y = layers.Activation('swish')(y)\n",
        "y = layers.Conv2D(1,(3,3),activation='sigmoid',padding='same')(y)\n",
        "decoder = Model([x,c],y)\n",
        "#decoder = Model(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "QNHwwTu_tcLR",
        "outputId": "188cc54c-7cf2-4feb-c420-04d5a5813ce9"
      },
      "outputs": [],
      "source": [
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lVRpt3c-0sH"
      },
      "outputs": [],
      "source": [
        "class KLDivergenceLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom Keras layer to calculate the KL divergence loss.\n",
        "\n",
        "    This layer ensures that the KL divergence calculation is performed\n",
        "    on concrete tensors during model execution, avoiding the error\n",
        "    \"ValueError: Tried to convert 'x' to a tensor and failed.\"\n",
        "    \"\"\"\n",
        "    def __init__(self, gamma=0.0001, **kwargs):\n",
        "        super(KLDivergenceLayer, self).__init__(**kwargs)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        # Calculate KL divergence loss\n",
        "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        # Apply gamma scaling\n",
        "        kl_loss = self.gamma * kl_loss\n",
        "        # Add the KL loss as an activity regularization loss\n",
        "        self.add_loss(K.mean(kl_loss))\n",
        "        # Return the original inputs unchanged\n",
        "        return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkMlqvXMLa2U"
      },
      "outputs": [],
      "source": [
        "x = layers.Input(shape=input_dim)\n",
        "c = layers.Input(shape=(10,))\n",
        "z_mean, z_log_var = encoder([x,c])\n",
        "z_mean, z_log_var = KLDivergenceLayer()([z_mean, z_log_var])\n",
        "z = layers.Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "x_hat = decoder([z,c]) #z\n",
        "cvae = Model([x,c],x_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "YIoOOU0Jyzf1",
        "outputId": "d30b08f7-c9cb-4d66-82c2-e8d55f98a117"
      },
      "outputs": [],
      "source": [
        "cvae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW5H-gc8-oy0"
      },
      "source": [
        "We decode the image starting from the latent representation z and its category y, that must be concatenated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-NDaqVC-7-3"
      },
      "source": [
        "The VAE loss function is just the sum between the reconstruction error (mse or bce) and the KL-divergence, acting as a regularizer of the latent space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xOz-Dsn1JIj"
      },
      "outputs": [],
      "source": [
        "def vae_loss(y_true, y_pred):\n",
        "    gamma = .0001  #balancing parameter\n",
        "    # Reconstruction loss\n",
        "    rec_loss = K.sum(metrics.mse(y_true, y_pred),axis=(1,2))\n",
        "    # KL divergence loss\n",
        "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    # Total VAE loss\n",
        "    total_loss = rec_loss + gamma*kl_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pXS7wjS85eD"
      },
      "source": [
        "Some hyperparameters. Gamma is used to balance loglikelihood and KL-divergence in the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBZvcj_VnRjE"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO5bJn1e_VcD"
      },
      "source": [
        "We are ready to compile. There is no need to specify the loss function, since we already added it to the model with add_loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Px-yKVV_sRH"
      },
      "outputs": [],
      "source": [
        "optimizer = optimizers.Adam(learning_rate=.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88MtVNBokxYM"
      },
      "outputs": [],
      "source": [
        "cvae.compile(optimizer=optimizer,loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I2N8blv_kT2"
      },
      "source": [
        "Train for a sufficient amount of epochs. Generation is a more complex task than classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z12B7w7zi_kv",
        "outputId": "f280542e-40ae-450b-9db6-e18e8f7824d7"
      },
      "outputs": [],
      "source": [
        "cvae.fit([x_train,y_train],x_train,epochs=30,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txKlTVhs_yeF"
      },
      "source": [
        "Let us decode the full test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbZ110fvm5GU",
        "outputId": "a0f55132-842f-45ac-bfd0-8708104b9226"
      },
      "outputs": [],
      "source": [
        "decoded_imgs = cvae.predict([x_test,y_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N0khSaF_6-8"
      },
      "source": [
        "The following function is to test the quality of reconstructions (not particularly good, since compression is strong)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhEuyvLqmg9Z"
      },
      "outputs": [],
      "source": [
        "def plot(n=10):\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "kts9354Pmq9Y",
        "outputId": "97280c11-a324-407b-e1c9-a5ba1d8e52bf"
      },
      "outputs": [],
      "source": [
        "plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADA_k_hLn_vU"
      },
      "source": [
        "Finally, we build a digit generator that can sample from the learned distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRcV178se5zv"
      },
      "outputs": [],
      "source": [
        "generator = decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpzeowOsAVEX"
      },
      "source": [
        "And we can generate our samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dXO1fys7ohKn",
        "outputId": "f27b9bd0-eca7-4f89-dc43-8b6b5e6bbf25"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# display a 2D manifold of the digits\n",
        "n = 3  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "while True:\n",
        "  label = input(\"input digit to generate: \\n\")\n",
        "  label = int(label)\n",
        "  if label < 0 or label > 9:\n",
        "      print(label)\n",
        "      break\n",
        "  label = np.expand_dims(utils.to_categorical(label,10),axis=0)\n",
        "  for i in range(0,n):\n",
        "    for j in range (0,n):\n",
        "        z_sample = np.expand_dims(np.random.normal(size=latent_dim),axis=0)\n",
        "        x_decoded = generator.predict([z_sample,label])\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "  plt.figure(figsize=(5, 5))\n",
        "  plt.imshow(figure, cmap='Greys_r')\n",
        "  plt.show()\n",
        "  time.sleep(1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
