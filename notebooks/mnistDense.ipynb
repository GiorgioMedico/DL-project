{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8wSwJnsjx5P"
      },
      "source": [
        "# Mnist classification with NNs\n",
        "A first example of a simple Neural Network, applied to a well known dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wMZ2Ge6jw1E"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Activation\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDiNppLVkvqd"
      },
      "source": [
        "Let us load the mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL8GyC0Nk14o",
        "outputId": "e0ea766d-1526-498b-e3dd-36c940949c53"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijhDuLwwlQrI",
        "outputId": "ff1302ed-3d3e-4a21-c017-4e61f860ddcf"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(\"pixel range is [{},{}]\".format(np.min(x_train),np.max(x_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D01L64YcnWO5"
      },
      "source": [
        "We normalize the input in the range [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8uA2Kp7mG9s"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = np.reshape(x_train,(60000,28*28))\n",
        "x_test = np.reshape(x_test,(10000,28*28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic2GXco9muen"
      },
      "source": [
        "Let us visualize a few images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "UlReb3tbmase",
        "outputId": "a88e321a-853f-4e46-8ea9-77eff920be90"
      },
      "outputs": [],
      "source": [
        "i = np.random.randint(0,60000)\n",
        "plt.imshow(x_train[i].reshape(28,28),cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjrzmhgh3TZv"
      },
      "source": [
        "The output of the network will be a probability distribution over the different categories. Similarly, we generate a ground truth distribution, and the training objective will consist in minimizing their distance (categorical crossentropy). The ground truth distribution is the so called \"categorical\" distribution: if x has label l, the corresponding categorical distribution has probaility 1 for the category l, and 0 for all the others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhzWUm0UnODb",
        "outputId": "77200923-018d-410d-cc73-722da7703253"
      },
      "outputs": [],
      "source": [
        "i = np.random.randint(0,60000)\n",
        "print(y_train[i])\n",
        "y_train_cat = utils.to_categorical(y_train)\n",
        "print(y_train_cat[i])\n",
        "y_test_cat = utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfeZF3bUrFZf"
      },
      "source": [
        "Our first Netwok just implements logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBJtMj2pqJiR"
      },
      "outputs": [],
      "source": [
        "xin = Input(shape=(28*28,))\n",
        "#x = Dense(64, activation='relu')(xin)\n",
        "x = Dense(10,activation='softmax')(xin)\n",
        "#res = Activation('softmax')(x)\n",
        "\n",
        "mynet = Model(inputs=[xin],outputs=[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "hXD5JT2ZrTJc",
        "outputId": "75850db6-7c25-4980-949e-ed34df38689b"
      },
      "outputs": [],
      "source": [
        "mynet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcjcOz8yrk5X"
      },
      "source": [
        "Now we need to compile the network.\n",
        "In order to do it, we need to pass two mandatory arguments:\n",
        "\n",
        "\n",
        "*   the **optimizer**, in charge of governing the details of the backpropagation algorithm\n",
        "*   the **loss function**\n",
        "\n",
        "Several predefined optimizers exist, and you should just choose your favourite one. A common choice is Adam, implementing an adaptive lerning rate, with momentum\n",
        "\n",
        "Optionally, we can specify additional metrics, mostly meant for monitoring the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XK20mAFrrkQ"
      },
      "outputs": [],
      "source": [
        "mynet.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E58bT-Imvsw2"
      },
      "source": [
        "Finally, we fit the model over the training set.\n",
        "\n",
        "Fitting, just requires two arguments: training data e ground truth, that is x and y. Additionally we can specify epochs, batch_size, and many additional arguments.\n",
        "\n",
        "In particular, passing validation data allow the training procedure to measure loss and metrics on the validation set at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2woDXbbr6ak",
        "outputId": "467415e6-9367-4d37-fa4f-aa1df83bdb10"
      },
      "outputs": [],
      "source": [
        "mynet.fit(x_train,y_train_cat, shuffle=True, epochs=5, batch_size=32,validation_data=(x_test,y_test_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcM6RkgsP5uS"
      },
      "outputs": [],
      "source": [
        "mynet.save_weights('myweights.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0mBuorMulG5"
      },
      "outputs": [],
      "source": [
        "xin = Input(shape=(784,))\n",
        "x = Dense(47,activation='relu')(xin)\n",
        "#x = BatchNormalization()(x)\n",
        "res = Dense(10,activation='softmax')(x)\n",
        "\n",
        "mynet2 = Model(inputs=xin,outputs=res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "SpMyvw7buzhT",
        "outputId": "160dcdf4-e61e-4c26-dc2a-5977b3c4f272"
      },
      "outputs": [],
      "source": [
        "mynet2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjbusR01rTbo"
      },
      "outputs": [],
      "source": [
        "mynet2.load_weights('myweights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYg0odW2u6cn"
      },
      "outputs": [],
      "source": [
        "mynet2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDnzgIZVvGOm",
        "outputId": "6d1a10e0-b121-49e2-bcc0-6b0c787cf441"
      },
      "outputs": [],
      "source": [
        "mynet2.fit(x_train,y_train_cat, shuffle=True, epochs=5, batch_size=32,validation_data=(x_test,y_test_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcwUqSVxprz6"
      },
      "outputs": [],
      "source": [
        "p = mynet.predict(x_test[1:2])\n",
        "print(p)\n",
        "print(np.argmax(p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31IzHQaKRTUa"
      },
      "outputs": [],
      "source": [
        "print(y_test[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvJLpDx1qud1"
      },
      "outputs": [],
      "source": [
        "mynet.save_weights('myweights')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcUKxCzKwzG9"
      },
      "source": [
        "An amazing improvement. WOW!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJr0EnAkw6nf"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1.   Add additional Dense layers and check the performance of the network\n",
        "2.   Replace 'relu' with different activation functions\n",
        "3. Adapt the network to work with the so called sparse_categorical_crossentropy\n",
        "4. the fit function return a history of training, with temporal sequences for all different metrics. Make a plot.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
