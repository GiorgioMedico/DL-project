{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haUUbAip1yDE"
   },
   "source": [
    "# Overfitting on the IMDB movie reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Alo9UeDCuPPV"
   },
   "source": [
    "In this notebook we shall focus on overfitting, demonstrating the phenomenon and studying techniques to address it. The dataset we shall use is the IMDB movie reviews dataset, composed of 25,000 movies reviews, labeled by sentiment (positive/negative).\n",
    "\n",
    "To prevent overfitting, the best solution is to use more training data. When that is not a viable possibility, you can try to use regularization techniques, constraining the quantity and quality of information stored by the model. If a network can only afford to memorize a small number of patterns, the optimization process will force it to focus on the most prominent ones, which have a better chance of generalizing well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSk2z9PFZ-9L"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import imdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztsNnb6iwK9C"
   },
   "source": [
    "Let us load the dataset. In keras, the dataset is preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4361,
     "status": "ok",
     "timestamp": 1741792002436,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "FJPbQOuMarDA"
   },
   "outputs": [],
   "source": [
    "num_words = 500\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\", num_words=num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRXaS5dmMpCF"
   },
   "source": [
    "Let us a look at the encoding of the first review.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1741792002442,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "xQjD51tfbAwr",
    "outputId": "479e600b-426e-4a2d-ed3c-02150f12fab6"
   },
   "outputs": [],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_52OeyDw7-2"
   },
   "source": [
    "This representation has a variable length dimension, that is not very stuitable for a neural network.\n",
    "\n",
    "Let us transform it into a multi_hot encoding of of dimension equal to num_words. In this representation, a word gets index 1 if it appears in the document. It is essentially a bag-of-words encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKJ17axp3bMX"
   },
   "source": [
    "\"this film is very bad\" -> 0\n",
    "\"this film is not so bad\" -> 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1520,
     "status": "ok",
     "timestamp": 1741792003964,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "alcGwlTXbK83"
   },
   "outputs": [],
   "source": [
    "def multi_hot_sequences(sequences, dimension):\n",
    "  multi_hot = np.zeros((len(sequences),dimension))\n",
    "  for i in range(0,len(sequences)):\n",
    "    multi_hot[i, sequences[i]] = 1\n",
    "  return multi_hot\n",
    "\n",
    "\n",
    "x_train = multi_hot_sequences(x_train, num_words)\n",
    "x_test = multi_hot_sequences(x_test, num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8FqTkPgxeS3"
   },
   "source": [
    "Let us have a look at the initial part of the encoding for the first review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1741793611172,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "LEqk4W3nbaOi",
    "outputId": "7a499233-473e-4d64-c8c8-43320c92f98d"
   },
   "outputs": [],
   "source": [
    "print(x_train[0,0:30])\n",
    "\n",
    "print( x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaJM6ZdCxnu0"
   },
   "source": [
    "We now define our first model, that is just a concatenation of three dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1741792639232,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "fIh5mHNDbncA"
   },
   "outputs": [],
   "source": [
    "seq = Input(shape=(num_words,))\n",
    "x = Dense(64, activation='relu')(seq)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "base_model = Model(seq, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1741792640226,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "UDCNRoQLbszt",
    "outputId": "93661530-430e-4ea0-d91a-b91cbd54cbc0"
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dg7OlD3px5b5"
   },
   "source": [
    "We compile the model using adam as optimizer, and binary crossentropy (log likelyhood) as loss function. The fit function returns a history of the training, that can be later inspected. In addition to the loss function, that is the canonical metric used for training, we also ask the model to keep trace of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1741792641620,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "zN2Z1A6KcD5U"
   },
   "outputs": [],
   "source": [
    "base_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7736,
     "status": "ok",
     "timestamp": 1741792650266,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "mVhduLsrcObg",
    "outputId": "3385200b-106c-468c-b736-db7dfe3b00be"
   },
   "outputs": [],
   "source": [
    "base_history = base_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 6,\n",
    "    batch_size = 512,\n",
    "    validation_data = (x_test, y_test),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlIRDSnNy57N"
   },
   "source": [
    "Let us see the keys available in our history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1741792628679,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "-C0VudEIciL1",
    "outputId": "8a4ff164-9683-40ad-cb6c-d390b354fd39"
   },
   "outputs": [],
   "source": [
    "print(base_history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsvLwbjLzFUf"
   },
   "source": [
    "The following function allows us to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1741792651756,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "7TdM-_YpcyiZ",
    "outputId": "db70bf1e-de96-4e03-8e77-0bebdad14c41"
   },
   "outputs": [],
   "source": [
    "def plot_history(model_history,keys):\n",
    "    m,val_m = keys\n",
    "    plt.plot(model_history.history[m])\n",
    "    plt.plot(model_history.history[val_m])\n",
    "    plt.ylabel(m)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(base_history,['accuracy','val_accuracy'])\n",
    "plot_history(base_history,['loss','val_loss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXZ69_z61pTC"
   },
   "source": [
    "# Weight regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vt3bBvXZzMU0"
   },
   "source": [
    "Now we modify our base model adding regularizers.\n",
    "\n",
    "A common way to mitigate overfitting is to reduce the complexity of the network by forcing its weights to only take small values, making the distribution of weights more “regular”. This is called “weight regularization”, and it is done by adding to the loss function of the network an additional cost associated with having large weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1741794689553,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "s22gY8U1dkYo"
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "seq = Input(shape=(num_words,))\n",
    "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.005))(seq)\n",
    "x = Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.005))(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "l2reg_model = Model(seq, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741794695368,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "VDnk7L2Eeh7q"
   },
   "outputs": [],
   "source": [
    "l2reg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12715,
     "status": "ok",
     "timestamp": 1741795045477,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "4fuUgMPpewd_",
    "outputId": "36c41a24-f66e-4c05-fb87-249ebc9e69de"
   },
   "outputs": [],
   "source": [
    "l2reg_history = l2reg_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 15,\n",
    "    batch_size = 512,\n",
    "    validation_data = (x_test, y_test),\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1741795050495,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "t3TrT7ydfVgw",
    "outputId": "9eb9ac88-21d1-400d-bafa-310d5aba0d5f"
   },
   "outputs": [],
   "source": [
    "plot_history(l2reg_history,['accuracy','val_accuracy'])\n",
    "plot_history(l2reg_history,['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZs5oVRF0LAK"
   },
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtVCugQW09_1"
   },
   "source": [
    "Dropout is an alternativeregularization techniques for neural networks. It consists of randomly “dropping out” (i.e. set to zero) a number of output features of the layer during training.\n",
    "\n",
    "At test time, no units are dropped out, but the layer’s output values are scaled down by a factor equal to the dropout rate, so as to balance for the fact that more units are active than at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1741795510233,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "i_ZA6nn3hI8G"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyCHPs5W1XNo"
   },
   "source": [
    "Let’s add a couple of dropout layers in our IMDB network and see how it performs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1741795511227,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "XNNVUxxThTtO"
   },
   "outputs": [],
   "source": [
    "seq = Input(shape=(num_words,))\n",
    "x = Dense(64, activation='relu')(seq)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "dropout_model = Model(seq, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741795514069,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "MtwSyEeYh5jS"
   },
   "outputs": [],
   "source": [
    "dropout_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1741795515196,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "E-BUqoVgq1NE",
    "outputId": "58b52740-7ef1-438b-b2a7-f25fd9b257c4"
   },
   "outputs": [],
   "source": [
    "dropout_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6889,
     "status": "ok",
     "timestamp": 1741795578373,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "YdubTd_ViHz4",
    "outputId": "0819c30d-9b0c-42bf-84ae-0eede2de0d27"
   },
   "outputs": [],
   "source": [
    "dropout_history = dropout_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 5,\n",
    "    batch_size = 512,\n",
    "    validation_data = (x_test, y_test),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1741795581131,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "Wan5Jqhui3Rm",
    "outputId": "0c30ec6a-b76c-473b-9ee2-052e24b9de3a"
   },
   "outputs": [],
   "source": [
    "plot_history(dropout_history,['accuracy','val_accuracy'])\n",
    "plot_history(dropout_history,['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1741796634221,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "LGylsBlkqgsr"
   },
   "outputs": [],
   "source": [
    "seq = Input(shape=(num_words,))#bs,500\n",
    "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.005))(seq)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.005))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "mixed_model = Model(seq, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1741796637958,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "gD69SdvUrWD_"
   },
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(learning_rate=0.001)\n",
    "mixed_model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7041,
     "status": "ok",
     "timestamp": 1741795790267,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "MwsSSHyargi6",
    "outputId": "c74a1975-02a9-4e83-e08e-4b592ad3f910"
   },
   "outputs": [],
   "source": [
    "mixed_history = mixed_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 5,\n",
    "    batch_size = 512,\n",
    "    validation_data = (x_test, y_test),\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1741795795286,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "CMLhYwKII2rF",
    "outputId": "a825fddd-7319-4f9f-fec9-23dcbf89cc45"
   },
   "outputs": [],
   "source": [
    "plot_history(mixed_history,['accuracy','val_accuracy'])\n",
    "plot_history(mixed_history,['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQPVeOrtM8Lf"
   },
   "source": [
    "# Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGRc8KPkS5cN"
   },
   "source": [
    "Early stopping is a method that allows you to stop training as soon as the model performance stops improving on the validation dataset.\n",
    "\n",
    "This requires that a validation set must be provided to the fit() function.\n",
    "\n",
    "Early stopping can be simply implemented in keras using callbacks.\n",
    "A callback is a function taht is called at specific stages of the training procedure: start/end of epochs, start end of minibatches, etc.\n",
    "\n",
    "You can use callbacks to get a view on internal states and statistics of the model during training. A list of callbacks can be passed to the .fit() function using the keyword argument \"callbacks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1741796772546,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "x-ZKC8eqNAxd"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "\n",
    "saveDir = os.path.join(os.getcwd(), 'saved_models')\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.makedirs(saveDir)\n",
    "\n",
    "chkpt = os.path.join(saveDir, 'Cifar10_to256.keras')\n",
    "\n",
    "mixed_model.load_weights(chkpt)\n",
    "\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "cp_cb = ModelCheckpoint(filepath=chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5241,
     "status": "ok",
     "timestamp": 1741796972537,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "qvoIFERUP7Wl",
    "outputId": "73e134e2-3b75-45b2-a1bb-06711662fac4"
   },
   "outputs": [],
   "source": [
    "mixed_model.fit(x_train, y_train,\n",
    "                batch_size=512, #batch_size,\n",
    "                epochs= 20,\n",
    "                verbose=2,\n",
    "                validation_data=(x_test,y_test),\n",
    "                callbacks=[es_cb, cp_cb],\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1597,
     "status": "ok",
     "timestamp": 1741796780493,
     "user": {
      "displayName": "Salvatore Fiorilla",
      "userId": "08470273097812624739"
     },
     "user_tz": -60
    },
    "id": "zLIxE8L6RTRk",
    "outputId": "9215b755-2526-4c1e-e460-eb3618e07d37"
   },
   "outputs": [],
   "source": [
    "loss,acc = mixed_model.evaluate(x_test,y_test)\n",
    "print(\"test loss = \", loss)\n",
    "print(\"test accuracy = \", acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1JkLZ6_LZ731ErQP49iFMTPQXbCX5RBmi",
     "timestamp": 1741781070167
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
